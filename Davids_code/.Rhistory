if(new_s == 0 | n_gen == max_g) break
if(n_gen == 0){
new_s <- g1(new_s, lambda, p) %>% sum
} else {
new_s <- g1(new_s, lambda, p) %>% sum
}
# save the results
n_gen <- n_gen + 1
sim_results$n_s[n_gen + 1] <- new_s
}
sim_results <- sim_results %>%
filter(complete.cases(.)) %>%
mutate(t_s = sum(n_s)) %>%
slice(1:(n()-1))
return(sim_results)
}
r_bp_sim()
sim_res <-
tibble(sim = 1:5000, sim_res = list(NULL)) %>%
group_by(sim) %>%
mutate(sim_res = list(r_bp_sim())) %>%
unnest(sim_res) %>%
slice(n()) %>% ungroup()
sim_res %>% count(t_s) %>%
mutate(p = n/sum(n)) %>%
ggplot(aes(x = t_s, y = p)) +
geom_point() +
scale_y_log10()
sim_res %>% summarise(mean(t_s))
# source('./code/_project_setup.r')
library(tidyverse)
prob_ex_pois <- function(k, lambda)((k + 1)/ lambda) * dpois(k + 1, lambda)
dpois(0:10, 9) %>% round(2)
rex_pois <- function(n, lambda) sample(x = 0:100, n, replace = T, prob = prob_ex_pois(0:100, lambda))
g1 <- function(n, lambda, p) rbinom(1, rpois(n, lambda), p)
g <- function(n, lambda, p) rbinom(1, rex_pois(n, lambda), p)
# g1 <- function(n, lambda, p) rbinom(1, 6, p)
# g <- function(n, lambda, p) rbinom(1, 5, p)
r_bp_sim <- function(max_g = 10^5, lambda = 6, p = 0.05){
# setup simulation
sim_results <- tibble(n_gen = 0:max_g, n_s = NA)
n_gen <- 0; new_s <- 1;
# do the simulation
sim_results$n_s[n_gen + 1] <- new_s
repeat{
if(new_s == 0 | n_gen == max_g) break
if(n_gen == 0){
new_s <- g1(new_s, lambda, p) %>% sum
} else {
new_s <- g1(new_s, lambda, p) %>% sum
}
# save the results
n_gen <- n_gen + 1
sim_results$n_s[n_gen + 1] <- new_s
}
sim_results <- sim_results %>%
filter(complete.cases(.)) %>%
mutate(t_s = sum(n_s)) %>%
slice(1:(n()-1))
return(sim_results)
}
r_bp_sim()
sim_res <-
tibble(sim = 1:5000, sim_res = list(NULL)) %>%
group_by(sim) %>%
mutate(sim_res = list(r_bp_sim())) %>%
unnest(sim_res) %>%
slice(n()) %>% ungroup()
sim_res %>% count(t_s) %>%
mutate(p = n/sum(n)) %>%
ggplot(aes(x = t_s, y = p)) +
geom_point() +
scale_y_log10()
prob_ex_pois <- function(k, lambda)((k + 1)/ lambda) * dpois(k + 1, lambda)
dpois(0:10, 9) %>% round(2)
rex_pois <- function(n, lambda) sample(x = 0:100, n, replace = T, prob = prob_ex_pois(0:100, lambda))
g1 <- function(n, lambda, p) rbinom(1, rpois(n, lambda), p)
g <- function(n, lambda, p) rbinom(1, rex_pois(n, lambda), p)
# g1 <- function(n, lambda, p) rbinom(1, 6, p)
# g <- function(n, lambda, p) rbinom(1, 5, p)
r_bp_sim <- function(max_g = 10^5, lambda = 6, p = 0.05){
# setup simulation
sim_results <- tibble(n_gen = 0:max_g, n_s = NA)
n_gen <- 0; new_s <- 1;
# do the simulation
sim_results$n_s[n_gen + 1] <- new_s
repeat{
if(new_s == 0 | n_gen == max_g) break
if(n_gen == 0){
new_s <- g1(new_s, lambda, p) %>% sum
} else {
new_s <- g1(new_s, lambda, p) %>% sum
}
# save the results
n_gen <- n_gen + 1
sim_results$n_s[n_gen + 1] <- new_s
}
sim_results <- sim_results %>%
filter(complete.cases(.)) %>%
mutate(t_s = sum(n_s)) %>%
slice(1:(n()-1))
return(sim_results)
}
r_bp_sim()
r_mtbp_sim <- function(max_g = 5000, lambda_in = 3, lambda_out = 3,
p_in = 0.05, p_out = 0.05){
sim_results <- tibble(n_gen = 0:max_g, n_s1 = NA, n_s2 = NA)
n_gen <- 0; new_s1 <- 1; new_s2 <- 1;
# do the simulation
sim_results$n_s1[n_gen + 1] <- new_s1
sim_results$n_s2[n_gen + 1] <- new_s2
repeat{
if((new_s1 + new_s2 == 0) | n_gen == max_g) break
s1_temp <- new_s1
s2_temp <- new_s2
if(n_gen == 0){
new_s1 <- sum(g1(s1_temp, lambda_in, p_in), na.rm = TRUE) + sum(g1(s2_temp, lambda_out, p_out), na.rm = TRUE)
new_s2 <- sum(g1(s1_temp, lambda_out, p_out), na.rm = TRUE) + sum(g1(s2_temp, lambda_in, p_in), na.rm = TRUE)
} else {
new_s1 <- sum(g(s1_temp, lambda_in, p_in), na.rm = TRUE) + sum(g(s2_temp, lambda_out, p_out), na.rm = TRUE)
new_s2 <- sum(g(s1_temp, lambda_out, p_out), na.rm = TRUE) + sum(g(s2_temp, lambda_in, p_in), na.rm = TRUE)
}
# save the results
n_gen <- n_gen + 1
sim_results$n_s1[n_gen + 1] <- new_s1
sim_results$n_s2[n_gen + 1] <- new_s2
}
sim_results <- sim_results %>%
filter(complete.cases(.)) %>%
mutate(t_s1 = sum(n_s1), t_s2 = sum(n_s2), t_s = t_s1 + t_s2,
p_s1 = t_s1/t_s, p_s2 = 1 - p_s1) %>%
slice(1:(n()-1))
return(sim_results)
}
sim_res <-
tibble(sim = 1:5000, sim_res = list(NULL)) %>%
group_by(sim) %>%
mutate(sim_res = list(r_mtbp_sim())) %>%
unnest(sim_res) %>%
slice(n()) %>%
ungroup()
# sim_res %>% count(t_s) %>% mutate(p = n/sum(n)) %>%
#   ggplot(aes(x = t_s, y = p)) +
#   geom_point() +
#   scale_x_log10() +
#   scale_y_log10()
#
sim_res %>%
# filter(p_s1 != 1) %>%
# filter(t_s > 1) %>%
ggplot(aes(x = p_s1)) +
geom_histogram(color = 'black', fill = 'gold', bins = 100)
sim_res %>%
select(t_s, t_s1, t_s2, p_s1) %>%
mutate(p_s2 = 1 - p_s1) %>%
as.matrix() %>%
cov()
sim_res %>% # filter(n_gen > 0) %>%
# select(t_s,t_s1, t_s2, p_s1) %>%
mutate(p_s2 = 1 - p_s1) %>%
summarise(
max(n_gen),
mt_s = mean(t_s), mt_s1 = mean(t_s1), mt_s2 = mean(t_s2),
p_s1 = mean(p_s1), p_s2 = mean(p_s2),
cov12 = cov(t_s1,t_s2), var1 = var(t_s1), var2 = var(t_s2),
cov1 = cov(t_s,t_s1), vart = var(t_s),
) %>%
mutate(
est_s1moment = mt_s1/mt_s,
est_2 = est_s1moment - (cov1/(mt_s^2)) + (vart * mt_s1)/(mt_s^3)
) %>%
mutate(
exp_ts12 = mt_s1/(mt_s1 + mt_s2) + (2*mt_s1*cov12)/(mt_s1 + mt_s2)^3 - cov12/(mt_s1 + mt_s2)^2 + (mt_s1*var1)/(mt_s1 + mt_s2)^3 - var1/(mt_s1 + mt_s2)^2 + (mt_s1*var2)/(mt_s1 + mt_s2)^3
)
r_mtbp_sim <- function(max_g = 5000, lambda_in = 6, lambda_out = 2,
p_in = 0.05, p_out = 0.05){
sim_results <- tibble(n_gen = 0:max_g, n_s1 = NA, n_s2 = NA)
n_gen <- 0; new_s1 <- 2; new_s2 <- 1;
# do the simulation
sim_results$n_s1[n_gen + 1] <- new_s1
sim_results$n_s2[n_gen + 1] <- new_s2
repeat{
if((new_s1 + new_s2 == 0) | n_gen == max_g) break
s1_temp <- new_s1
s2_temp <- new_s2
if(n_gen == 0){
new_s1 <- sum(g1(s1_temp, lambda_in, p_in), na.rm = TRUE) + sum(g1(s2_temp, lambda_out, p_out), na.rm = TRUE)
new_s2 <- sum(g1(s1_temp, lambda_out, p_out), na.rm = TRUE) + sum(g1(s2_temp, lambda_in, p_in), na.rm = TRUE)
} else {
new_s1 <- sum(g(s1_temp, lambda_in, p_in), na.rm = TRUE) + sum(g(s2_temp, lambda_out, p_out), na.rm = TRUE)
new_s2 <- sum(g(s1_temp, lambda_out, p_out), na.rm = TRUE) + sum(g(s2_temp, lambda_in, p_in), na.rm = TRUE)
}
# save the results
n_gen <- n_gen + 1
sim_results$n_s1[n_gen + 1] <- new_s1
sim_results$n_s2[n_gen + 1] <- new_s2
}
sim_results <- sim_results %>%
filter(complete.cases(.)) %>%
mutate(t_s1 = sum(n_s1), t_s2 = sum(n_s2), t_s = t_s1 + t_s2,
p_s1 = t_s1/t_s, p_s2 = 1 - p_s1) %>%
slice(1:(n()-1))
return(sim_results)
}
sim_res <-
tibble(sim = 1:5000, sim_res = list(NULL)) %>%
group_by(sim) %>%
mutate(sim_res = list(r_mtbp_sim())) %>%
unnest(sim_res) %>%
slice(n()) %>%
ungroup()
# sim_res %>% count(t_s) %>% mutate(p = n/sum(n)) %>%
#   ggplot(aes(x = t_s, y = p)) +
#   geom_point() +
#   scale_x_log10() +
#   scale_y_log10()
#
sim_res %>%
# filter(p_s1 != 1) %>%
# filter(t_s > 1) %>%
ggplot(aes(x = p_s1)) +
geom_histogram(color = 'black', fill = 'gold', bins = 100)
sim_res %>%
select(t_s, t_s1, t_s2, p_s1) %>%
mutate(p_s2 = 1 - p_s1) %>%
as.matrix() %>%
cov()
sim_res %>% # filter(n_gen > 0) %>%
# select(t_s,t_s1, t_s2, p_s1) %>%
mutate(p_s2 = 1 - p_s1) %>%
summarise(
max(n_gen),
mt_s = mean(t_s), mt_s1 = mean(t_s1), mt_s2 = mean(t_s2),
p_s1 = mean(p_s1), p_s2 = mean(p_s2),
cov12 = cov(t_s1,t_s2), var1 = var(t_s1), var2 = var(t_s2),
cov1 = cov(t_s,t_s1), vart = var(t_s),
) %>%
mutate(
est_s1moment = mt_s1/mt_s,
est_2 = est_s1moment - (cov1/(mt_s^2)) + (vart * mt_s1)/(mt_s^3)
) %>%
mutate(
exp_ts12 = mt_s1/(mt_s1 + mt_s2) + (2*mt_s1*cov12)/(mt_s1 + mt_s2)^3 - cov12/(mt_s1 + mt_s2)^2 + (mt_s1*var1)/(mt_s1 + mt_s2)^3 - var1/(mt_s1 + mt_s2)^2 + (mt_s1*var2)/(mt_s1 + mt_s2)^3
)
r_mtbp_sim <- function(max_g = 5000, lambda_in = 6, lambda_out = 6,
p_in = 0.05, p_out = 0.05){
sim_results <- tibble(n_gen = 0:max_g, n_s1 = NA, n_s2 = NA)
n_gen <- 0; new_s1 <- 1; new_s2 <- 0;
# do the simulation
sim_results$n_s1[n_gen + 1] <- new_s1
sim_results$n_s2[n_gen + 1] <- new_s2
repeat{
if((new_s1 + new_s2 == 0) | n_gen == max_g) break
s1_temp <- new_s1
s2_temp <- new_s2
if(n_gen == 0){
new_s1 <- sum(g1(s1_temp, lambda_in, p_in), na.rm = TRUE) + sum(g1(s2_temp, lambda_out, p_out), na.rm = TRUE)
new_s2 <- sum(g1(s1_temp, lambda_out, p_out), na.rm = TRUE) + sum(g1(s2_temp, lambda_in, p_in), na.rm = TRUE)
} else {
new_s1 <- sum(g(s1_temp, lambda_in, p_in), na.rm = TRUE) + sum(g(s2_temp, lambda_out, p_out), na.rm = TRUE)
new_s2 <- sum(g(s1_temp, lambda_out, p_out), na.rm = TRUE) + sum(g(s2_temp, lambda_in, p_in), na.rm = TRUE)
}
# save the results
n_gen <- n_gen + 1
sim_results$n_s1[n_gen + 1] <- new_s1
sim_results$n_s2[n_gen + 1] <- new_s2
}
sim_results <- sim_results %>%
filter(complete.cases(.)) %>%
mutate(t_s1 = sum(n_s1), t_s2 = sum(n_s2), t_s = t_s1 + t_s2,
p_s1 = t_s1/t_s, p_s2 = 1 - p_s1) %>%
slice(1:(n()-1))
return(sim_results)
}
sim_res <-
tibble(sim = 1:5000, sim_res = list(NULL)) %>%
group_by(sim) %>%
mutate(sim_res = list(r_mtbp_sim())) %>%
unnest(sim_res) %>%
slice(n()) %>%
ungroup()
# sim_res %>% count(t_s) %>% mutate(p = n/sum(n)) %>%
#   ggplot(aes(x = t_s, y = p)) +
#   geom_point() +
#   scale_x_log10() +
#   scale_y_log10()
#
sim_res %>%
# filter(p_s1 != 1) %>%
# filter(t_s > 1) %>%
ggplot(aes(x = p_s1)) +
geom_histogram(color = 'black', fill = 'gold', bins = 100)
sim_res %>%
select(t_s, t_s1, t_s2, p_s1) %>%
mutate(p_s2 = 1 - p_s1) %>%
as.matrix() %>%
cov()
sim_res %>% # filter(n_gen > 0) %>%
# select(t_s,t_s1, t_s2, p_s1) %>%
mutate(p_s2 = 1 - p_s1) %>%
summarise(
max(n_gen),
mt_s = mean(t_s), mt_s1 = mean(t_s1), mt_s2 = mean(t_s2),
p_s1 = mean(p_s1), p_s2 = mean(p_s2),
cov12 = cov(t_s1,t_s2), var1 = var(t_s1), var2 = var(t_s2),
cov1 = cov(t_s,t_s1), vart = var(t_s),
) %>%
mutate(
est_s1moment = mt_s1/mt_s,
est_2 = est_s1moment - (cov1/(mt_s^2)) + (vart * mt_s1)/(mt_s^3)
) %>%
mutate(
exp_ts12 = mt_s1/(mt_s1 + mt_s2) + (2*mt_s1*cov12)/(mt_s1 + mt_s2)^3 - cov12/(mt_s1 + mt_s2)^2 + (mt_s1*var1)/(mt_s1 + mt_s2)^3 - var1/(mt_s1 + mt_s2)^2 + (mt_s1*var2)/(mt_s1 + mt_s2)^3
)
p_cc_basic <- function(q1 = 0.995, alpha, n){
return(1-q1*(1-alpha)**(n-1))
}
# same as before but with a threshold m
p_cc_threshold <- function(q1 = 0.998, alpha, n, m){
vals <- numeric(length(n))
vals[which(n<m)] <- 1-q1*(1-alpha[which(n<m)])**(n[which(n<m)]-1)
vals[which(n>=m)] <- 1-q1*(1-alpha[which(n>=m)])**(m-1)
return(vals)
}
# this is from when we were looking at the probability of adoption decreasing after
# a certain number of exposures
p_cc_threshold_drop2 <- function(q1 = 0.998, alpha, n, m = 5, beta = 0.5){
vals <- numeric(length(n))
vals[which(n<m)] <- 1-q1*(1-alpha[which(n<m)])**(n[which(n<m)]-1)
vals[which(n>=m)] <- beta*(1-q1*(1-alpha[which(n>=m)])**(m-1))
return(vals)
}
# has been altered to regular threshold version, fix seed
# you will probably need to specify a different seed, or I usually like to pick a random one each time
generate_cc_cascades <- function(follower.net = follower.net, follower.adj = follower.adj, q1 = 0.998, alpha = 0.002, total = 1000, seed_ = NULL){
all_cascades.df <- tibble(parent = character(), child = character(), generation = numeric(), ID = numeric(), exposures = numeric())
for (j in 1:total) {
active <- numeric()
inactive <- numeric()
removed <- numeric()
vertex_names <- vertex_attr(follower.net)$name
if(is.null(seed_)){
seed <- sample(vertex_names,1)
active <- seed
} else {
active <- seed_
}
inactive <- vertex_names[! vertex_names %in% seed]
exposures <- numeric(gorder(follower.net))
names(exposures) <- vertex_names
cascade.df <- tibble(parent = character(), child = character(), generation = numeric())
generation <- 1
while (length(active)>0) {
new_active <- character()
# shuffle active
if(length(active)>1){
active <- sample(active)
}
for (i in active) {
followers <- vertex_names[which(follower.adj[,i]==1)]
potential_adopters <- followers[followers %in% inactive]
exposures[potential_adopters] <- exposures[potential_adopters] + 1
if(length(potential_adopters)>0){
# fix this, problem is with having n a vector
adopters <- potential_adopters[runif(length(potential_adopters)) < p_cc_threshold(q1 = q1, alpha = rep(alpha, length(potential_adopters)), n = exposures[potential_adopters], m = 5)]
if(length(adopters)>0){
new_active <- c(new_active, adopters)
inactive <- inactive[! inactive %in% new_active]
cascade.df <- cascade.df %>% add_row(parent = rep(i, length(adopters)), child = adopters, generation = rep(generation, length(adopters)))
}
}
}
generation <- generation + 1
removed <- c(removed, active)
active <- new_active
}
if(nrow(cascade.df)>0){
all_cascades.df <- all_cascades.df %>% add_row(cascade.df %>% mutate(ID = rep(j, nrow(cascade.df)), exposures = exposures[cascade.df$child]))
}
}
return(all_cascades.df)
}
igraph::erdos.renyi.game(1000, 0.1)
install.packages('rcoo')
install.packages('rcpp')
install.packages('Rcpp')
#include <Rcpp.h>
using namespace Rcpp;
library(Rcpp)
Rcpp::sourceCpp(file = 'test_c.cpp')
factorial
factorial(10)
Rcpp::sourceCpp('test_c.cpp')
factorial(10)
10!
10!
###############################################################################################
## Project: cross community cascade diffusion
## Script purpose: create the multitype branching processes sim code
## Date: 01-05-2022
## Author: David JP O'Sullivan
###############################################################################################
rm(list = ls()) # tidy work space
gc()
# libraries, source files and data ---------------------------------------------
# load in packages and codde
# source('./code/_project_setup.r')
source('./code/_code.R')
library(tidyverse) # load required packages
# bp simulations ----------------------------------------------------------
prob_ex_pois <- function(k, lambda)((k + 1)/ lambda) * dpois(k + 1, lambda)
# create the excess degree distrubion for a poi random var (we actually dont need
# this)
dpois(0:10, 9) %>% round(2) # see what the prob dist looks like
# create a function to sample n iid from the excess dist
rex_pois <- function(n, lambda) sample(x = 0:100, n, replace = T, prob = prob_ex_pois(0:100, lambda))
# create a function for the offspring distrubtion that gives the number of
# of infections if we have  rpois(n, lambda) links
g1 <- function(n, lambda, p) rbinom(1, rpois(n, lambda), p)
g <- function(n, lambda, p) rbinom(1, rex_pois(n, lambda), p)
# the excess degree dist for a sbm is also poi with the same parameter
# but its handy to build in the logic if we want to change it later
# multitype code ----------------------------------------------------------
r_mtbp_sim <- function(max_g = 5000, lambda_in = 6, lambda_out = 6,
p_in = 0.05, p_out = 0.05){
# create the data frame to hold the results of the sim
sim_results <- tibble(n_gen = 0:max_g, n_s1 = NA, n_s2 = NA)
# what generation do we start at; initial conditions for s1 and
# s2 types
n_gen <- 0; new_s1 <- 1; new_s2 <- 0;
# do the simulation by:
# first saving the initial coniditions
sim_results$n_s1[n_gen + 1] <- new_s1
sim_results$n_s2[n_gen + 1] <- new_s2
repeat{ # and repeating the following processes
# until there are no new types or may gen is reached
if((new_s1 + new_s2 == 0) | n_gen == max_g) break
# save the number of nodes of each type in a temp var
s1_temp <- new_s1
s2_temp <- new_s2
# if we are not beyond the seed generation
if(n_gen == 0){
# simuate the number of new s1 and s2 ndoes by
# finding the number of of s1 of sprind that all s1 and s2 nodes have had
new_s1 <- sum(g1(s1_temp, lambda_in, p_in), na.rm = TRUE) + sum(g1(s2_temp, lambda_out, p_out), na.rm = TRUE)
# same as above but for s2 offspring that s1 and s2 have had
new_s2 <- sum(g1(s1_temp, lambda_out, p_out), na.rm = TRUE) + sum(g1(s2_temp, lambda_in, p_in), na.rm = TRUE)
} else { # but same as above but using the excess degree dist
new_s1 <- sum(g(s1_temp, lambda_in, p_in), na.rm = TRUE) + sum(g(s2_temp, lambda_out, p_out), na.rm = TRUE)
new_s2 <- sum(g(s1_temp, lambda_out, p_out), na.rm = TRUE) + sum(g(s2_temp, lambda_in, p_in), na.rm = TRUE)
}
# save the results
n_gen <- n_gen + 1
sim_results$n_s1[n_gen + 1] <- new_s1
sim_results$n_s2[n_gen + 1] <- new_s2
}
# once we have finished the simulation
sim_results <- sim_results %>% # clean the results by
filter(complete.cases(.)) %>% # making sure there is no NA values
mutate( # adding col to the data
# that are the total number of s1, s2 and over all cascades sizes
t_s1 = sum(n_s1), t_s2 = sum(n_s2), t_s = t_s1 + t_s2,
# along with the proportion of different types in the
# cascade
p_s1 = t_s1/t_s, p_s2 = 1 - p_s1) %>%
slice(1:(n()-1))
return(sim_results) # return the data frame
}
sim_res <- # run the above code by:
tibble(
sim = 1:50, # setting up the number of monte carlo simulations
sim_res = list(NULL) # and a list to store the resutls of each sim
) %>%
group_by(sim) %>% # for each sim id
mutate(sim_res = list(r_mtbp_sim())) %>% # run the multi type bp sim and save the results
unnest(sim_res) %>%
slice(n()) %>%
ungroup()
head(sim_res)
# the following code does a network base simulation of the above branching processes
library(igraph)
p_in <- 9/(1000)  # for the network size what should be the p_in and p_out for the SBM
p_out <- 4/(1000)
# create the matrix for how the communities are connected
pm <- matrix(c(p_in, p_out, p_out, p_in), byrow = TRUE, nrow = 2)
res_df <- tibble() # create where we are going to store the result
for(i in 1:5000){ # for each i in the number sim we want to run
# sample a sbm network
g_temp <- sample_sbm(2000, pm, c(1000,1000), directed = FALSE)
# g_temp <- erdos.renyi.game(1000, p_in)
# try({
# g_temp <- sample_degseq(out.deg = rpois(n = 10000, lambda = 9))
# g_temp <- k.regular.game(1000,k = 6)
# degree(g_temp) %>% mean
# degree_distribution(g_temp)
# cluster.distribution(g_temp)
# give the nodes names (the sim code need this)
V(g_temp)$name <- 1:vcount(g_temp) %>% as.character()
seed <- sample(V(g_temp)$name[1:1000], 1) # make sure the sim always selects
# a node in s1
# then generate the sim by
temp <- generate_cc_cascades(
# using the sbm network we created
follower.net = g_temp, follower.adj = get.adjacency(g_temp),
# using this probability of not adopting (1 - prob of adopt)
q1 = 1 - 0.05, alpha = 0, total = 1, seed_ = seed) %>%
mutate(ID = i) # add a col that has the sim id
# if at least one link was created add to results
if(nrow(temp) > 0) res_df <- bind_rows(res_df, temp)
# },silent = TRUE)
}
head(res_df)
